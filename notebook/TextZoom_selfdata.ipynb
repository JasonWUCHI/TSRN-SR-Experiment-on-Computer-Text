{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LUpgewu3ypff",
        "sgy5yrw3kc-1",
        "j2uzzfcFSCXG",
        "QTLgDfbLOT7k",
        "cAkdc1qC5xgx",
        "VPD4j2Igh7PC"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUpgewu3ypff"
      },
      "source": [
        "#Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHFXAetHyo3J"
      },
      "source": [
        "BatchSize = 4\n",
        "train_path = '/content/content/train_jpeg'\n",
        "eval_path = '/content/content/eval_jpeg'\n",
        "image_Height = 256\n",
        "image_Width = 256\n",
        "downSample = 4\n",
        "\n",
        "#Model\n",
        "srb = 2\n",
        "hd_u = 32\n",
        "\n",
        "#Loss\n",
        "grd = True #gradient\n",
        "\n",
        "#Optimizer\n",
        "learning_rate = 0.001\n",
        "epochs = 500\n",
        "beta1 = 0.5\n",
        "\n",
        "#loss tracking\n",
        "training_loss = []\n",
        "eval_loss = []\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p996WalRl01"
      },
      "source": [
        "#Load Image from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In4eLQYUEA8T",
        "outputId": "18af0fa5-97fb-40b2-b431-6023ce80b8bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create dataset"
      ],
      "metadata": {
        "id": "sgy5yrw3kc-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "2siSvBxRket8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO3oKpbbkfwg",
        "outputId": "0ead3b9a-795d-4059-b10d-14232ab9bd4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self , sr_dir, blur_dir):\n",
        "    self.sr_dir = sr_dir\n",
        "    self.blur_dir = blur_dir\n",
        "    self.toTensor = transforms.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.sr_dir))\n",
        "\n",
        "  def __getitem__(self , idx):\n",
        "    img_path = os.path.join(self.sr_dir , \"%d.png\" % idx)\n",
        "    sr_img = self.toTensor(Image.open(img_path).convert('RGB'))\n",
        "    img_path = os.path.join(self.blur_dir , \"%d.png\" % idx)\n",
        "    blur_img = self.toTensor(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "\n",
        "    return sr_img, blur_img"
      ],
      "metadata": {
        "id": "WvVOSFi6kiOd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sr_dir = \"/content/gdrive/MyDrive/imgs\"\n",
        "blur_dir = \"/content/gdrive/MyDrive/blur_imgs\"\n",
        "dataset = MyDataset(sr_dir, blur_dir)"
      ],
      "metadata": {
        "id": "_EflCBXcmT9Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator1 = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.7, 0.2, 0.1], generator=generator1)"
      ],
      "metadata": {
        "id": "h5MWH014lbe8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset , batch_size = BatchSize , shuffle = True,)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset , batch_size = BatchSize , shuffle = True,)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset , batch_size = BatchSize , shuffle = True,)"
      ],
      "metadata": {
        "id": "2fdpIZyrlK9d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uzzfcFSCXG"
      },
      "source": [
        "#Create dataset old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIV53pRJC7T0"
      },
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from PIL import Image"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E3WXVb_5AXp",
        "outputId": "d09e5301-3c2d-46c8-af64-d63f77c4bcfe"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHs43uLud6PC"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self , img_dir , transform = None):\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir))\n",
        "\n",
        "  def __getitem__(self , idx):\n",
        "    img_path = os.path.join(self.img_dir , \"screenshot%05d.png\" % idx)\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqBup0a8ucda"
      },
      "source": [
        "class resizeNormalize(object):\n",
        "    def __init__(self, size, mask=False, interpolation=Image.BICUBIC):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "        self.toTensor = transforms.ToTensor()\n",
        "        self.mask = mask\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = img.resize(self.size, self.interpolation)\n",
        "        img_tensor = self.toTensor(img)\n",
        "        if self.mask:\n",
        "            mask = img.convert('L')\n",
        "            thres = np.array(mask).mean()\n",
        "            mask = mask.point(lambda x: 0 if x > thres else 255)\n",
        "            mask = self.toTensor(mask)\n",
        "            img_tensor = torch.cat((img_tensor, mask), 0)\n",
        "        return img_tensor\n",
        "\n",
        "class alignCollate_syn(object):\n",
        "    def __init__(self, imgH=64, imgW=256, down_sample_scale=4, keep_ratio=False, min_ratio=1, mask=False):\n",
        "        self.imgH = imgH\n",
        "        self.imgW = imgW\n",
        "        self.keep_ratio = keep_ratio\n",
        "        self.min_ratio = min_ratio\n",
        "        self.down_sample_scale = down_sample_scale\n",
        "        self.mask = mask\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        #images = zip(*batch)\n",
        "        images = batch\n",
        "        imgH = self.imgH\n",
        "        imgW = self.imgW\n",
        "        transform = resizeNormalize((imgW, imgH), self.mask)\n",
        "        transform2 = resizeNormalize((imgW // self.down_sample_scale, imgH // self.down_sample_scale), self.mask)\n",
        "\n",
        "        images_hr = [transform(image) for image in images]\n",
        "        images_hr = torch.cat([t.unsqueeze(0) for t in images_hr], 0)\n",
        "\n",
        "        images_lr = [image.resize((image.size[0]//self.down_sample_scale, image.size[1]//self.down_sample_scale), Image.BICUBIC) for image in images]\n",
        "        images_lr = [transform2(image) for image in images_lr]\n",
        "        images_lr = torch.cat([t.unsqueeze(0) for t in images_lr], 0)\n",
        "\n",
        "        return images_hr, images_lr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYbwL_zxR71n"
      },
      "source": [
        "# train_path = '/content/self_train_1'\n",
        "# train_dataset = MyDataset(train_path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcZL8QLhSYbu"
      },
      "source": [
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     train_dataset , batch_size = BatchSize , shuffle = True , collate_fn = alignCollate_syn(imgH = image_Height, imgW = image_Width, down_sample_scale=downSample, mask = True) , drop_last = True\n",
        "# )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ZkpBoxxfRb"
      },
      "source": [
        "#Building Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMsxjEs-xlyD"
      },
      "source": [
        "import math\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import sys\n",
        "from torch.nn import init\n",
        "from IPython import embed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlBPsrWc7V3U"
      },
      "source": [
        "class GruBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(GruBlock, self).__init__()\n",
        "    assert out_channels % 2 == 0\n",
        "    self.conv1 = nn.Conv2d(in_channels , out_channels , kernel_size=1 , padding = 0)\n",
        "    self.gru = nn.GRU(out_channels , out_channels // 2 , bidirectional = True , batch_first = True)\n",
        "\n",
        "  def forward(self , x):\n",
        "    x = self.conv1(x)\n",
        "    x = x.permute(0 , 2 , 3 ,1).contiguous()\n",
        "    b = x.size()\n",
        "    x = x.view(b[0] * b[1], b[2], b[3])\n",
        "    x , _ = self.gru(x)\n",
        "    x = x.view(b[0] , b[1] , b[2] , b[3])\n",
        "    x = x.permute(0 , 3 , 1 , 2)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMU0JO5X9xJB"
      },
      "source": [
        "class mish(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super(mish , self).__init__()\n",
        "    self.activated = True\n",
        "\n",
        "  def forward(self , x):\n",
        "    if self.activated:\n",
        "      x = x * (torch.tanh(F.softplus(x)))\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9mi3o4g5eSu"
      },
      "source": [
        "class RecurrentResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super(RecurrentResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(channels, channels, kernel_size = 3 , padding = 1)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.gru1 = GruBlock(channels , channels)\n",
        "    self.prelu = mish()\n",
        "    self.conv2 = nn.Conv2d(channels , channels , kernel_size=3 , padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "    self.gru2 = GruBlock(channels , channels)\n",
        "\n",
        "  def forward(self , x):\n",
        "    residual = self.conv1(x)\n",
        "    residual = self.bn1(residual)\n",
        "    residual = self.prelu(residual)\n",
        "    residual = self.conv2(residual)\n",
        "    residual = self.bn2(residual)\n",
        "    residual = self.gru1(residual.transpose(-1 , -2)).transpose(-1,-2)\n",
        "\n",
        "    return self.gru2(x+residual)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd7Xz4vwF1yT"
      },
      "source": [
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels , upscale):\n",
        "    super(UpsampleBlock , self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels , in_channels * upscale ** 2 , kernel_size=3 , padding=1)\n",
        "    self.pixel_shuffle = nn.PixelShuffle(upscale)\n",
        "    self.prelu = mish()\n",
        "\n",
        "  def forward(self , x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pixel_shuffle(x)\n",
        "    x = self.prelu(x)\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udkr0HFM3LwF"
      },
      "source": [
        "class TSRN(nn.Module):\n",
        "  def __init__(self , scale_factor=4 , width=128 , height=32 , STN=False , srb_nums=5, mask=True, hidden_units=32 ):\n",
        "    super(TSRN, self).__init__()\n",
        "    in_planes = 3\n",
        "    if mask:\n",
        "      in_planes = 4\n",
        "\n",
        "    # assert math.log(scale_factor,2)%1 == 0\n",
        "    # upsample_block_num = int(math.log(scale_factor,2))\n",
        "\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_planes , 2* hidden_units , kernel_size=9 , padding = 4),\n",
        "        nn.PReLU()\n",
        "    )\n",
        "    self.srb_nums = srb_nums\n",
        "\n",
        "    srb_blocks = [RecurrentResidualBlock(2*hidden_units) for _ in range(srb_nums)]\n",
        "    srb_blocks += [nn.Conv2d(2*hidden_units , 2*hidden_units , kernel_size = 3 , padding=1),nn.BatchNorm2d(2*hidden_units)]\n",
        "    self.srb_blocks = nn.Sequential(*srb_blocks)\n",
        "    # for i in range(srb_nums):\n",
        "    #   setattr(self , 'block%d' % (i+2), RecurrentResidualBlock(2*hidden_units))\n",
        "\n",
        "    # setattr(self , 'block%d' % (srb_nums+2),\n",
        "    #         nn.Sequential(\n",
        "    #             nn.Conv2d(2*hidden_units , 2*hidden_units , kernel_size = 3 , padding=1),\n",
        "    #             nn.BatchNorm2d(2*hidden_units)\n",
        "    #         ))\n",
        "\n",
        "    # block_ = [UpsampleBlock(2*hidden_units , 2) for _ in range(upsample_block_num)]\n",
        "    # block_.append(nn.Conv2d(2*hidden_units , in_planes ,  kernel_size=9 , padding = 4))\n",
        "    # self.upsample_blocks = nn.Sequential(*block_)\n",
        "    self.upsample_blocks = nn.Conv2d(2*hidden_units , in_planes ,  kernel_size=9 , padding = 4)\n",
        "    #setattr(self, 'block%d' % (srb_nums+3) , nn.Sequential(*block_))\n",
        "\n",
        "    # self.tps_inputsize = [32, 64]\n",
        "    # tps_outputsize = [height//scale_factor, width//scale_factor]\n",
        "    # num_control_points = 20\n",
        "    # tps_margins = [0.05, 0.05]\n",
        "    # self.stn = STN\n",
        "    # if self.stn:\n",
        "    #     self.tps = TPSSpatialTransformer(\n",
        "    #         output_image_size=tuple(tps_outputsize),\n",
        "    #         num_control_points=num_control_points,\n",
        "    #         margins=tuple(tps_margins))\n",
        "\n",
        "    #     self.stn_head = STNHead(\n",
        "    #         in_planes=in_planes,\n",
        "    #         num_ctrlpoints=num_control_points,\n",
        "    #         activation='none')\n",
        "\n",
        "  def forward(self , x):\n",
        "    # if self.stn and self.training:\n",
        "    #   x = F.interpolate(x, self.tps_inputsize, mode='bilinear', align_corners=True)\n",
        "    #   _, ctrl_points_x = self.stn_head(x)\n",
        "    #   x, _ = self.tps(x, ctrl_points_x)\n",
        "    block = self.block1(x)\n",
        "    block2 = self.srb_blocks(block)\n",
        "    output = torch.tanh(self.upsample_blocks(block+block2))\n",
        "    # for i in range(self.srb_nums + 1):\n",
        "    #   block[str(i+2)] = getattr(self, 'block%d' % (i+2))(block[str(i+1)])\n",
        "\n",
        "    #block[str(self.srb_nums + 3)] = getattr(self, 'block%d' % (self.srb_nums + 3))((block['1'] + block[str(self.srb_nums + 2)]))\n",
        "    #output = torch.tanh(block[str(self.srb_nums + 3)])\n",
        "\n",
        "    #print(block['1'].shape, output.shape)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTLgDfbLOT7k"
      },
      "source": [
        "#Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNdMMU8N1m1t"
      },
      "source": [
        "class GradientPriorLoss(nn.Module):\n",
        "  def __init__(self , ):\n",
        "    super(GradientPriorLoss , self).__init__()\n",
        "    self.func = nn.L1Loss()\n",
        "\n",
        "  def forward(self , out_images , target_images):\n",
        "    map_out = self.gradient_map(out_images)\n",
        "    map_target = self.gradient_map(target_images)\n",
        "    return self.func(map_out , map_target)\n",
        "\n",
        "  @staticmethod\n",
        "  def gradient_map(x):\n",
        "    batch_size , channel , h_x , w_x = x.size()\n",
        "    r = F.pad(x , (0,1,0,0))[: , : , : , 1:]\n",
        "    l = F.pad(x , (1,0,0,0))[: , : , : , :w_x]\n",
        "    t = F.pad(x , (0,0,1,0))[: , : , :h_x , :]\n",
        "    b = F.pad(x , (0,0,0,1))[: , : , 1: , :]\n",
        "    xgrad = torch.pow(torch.pow((r-l)*0.5 , 2) + torch.pow((t-b)*0.5 , 2)+1e-6 , 0.5)\n",
        "    return xgrad"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQDBouv7OTIU"
      },
      "source": [
        "class ImageLoss(nn.Module):\n",
        "  def __init__(self , gradient = True , loss_weight = [20 , 1e-4]):\n",
        "    super(ImageLoss , self).__init__()\n",
        "    self.mse = nn.MSELoss()\n",
        "    if gradient:\n",
        "      self.GPLoss = GradientPriorLoss()\n",
        "    self.gradient = gradient\n",
        "    self.loss_weight = loss_weight\n",
        "\n",
        "  def forward(self , out_images, target_images):\n",
        "    if self.gradient:\n",
        "      loss = self.loss_weight[0] * self.mse(out_images , target_images) + \\\n",
        "             self.loss_weight[1] * self.GPLoss(out_images[: , :3 , : , :], target_images[: , :3 , : , :])\n",
        "    else:\n",
        "      loss = self.loss_weight[0] * self.mse(out_images , target_images)\n",
        "    return loss\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training New"
      ],
      "metadata": {
        "id": "VeAi2ziPrHLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  model = model.to(device)\n",
        "  image_crit = ImageLoss(gradient=grd, loss_weight=[1 , 1e-4])\n",
        "  image_crit = image_crit.to(device)\n",
        "  optimizer_G = torch.optim.Adam(model.parameters() , lr=learning_rate , betas=(beta1,0.999))\n",
        "\n",
        "  for epoch in range(5):\n",
        "    print(\"Number of epoch:\" , epoch)\n",
        "    for j, data in (enumerate(train_loader)):\n",
        "      model.train() #verify that model is training instead of evaluating\n",
        "      iters = len(train_loader) * epoch + j + 1\n",
        "      optimizer_G.zero_grad()\n",
        "\n",
        "      images_hr , images_lr = data #[16,3,256,256]\n",
        "      images_lr = images_lr.to(device)\n",
        "      images_hr = images_hr.to(device)\n",
        "      image_sr = model(images_lr)\n",
        "      print(images_hr.shape, images_lr.shape, image_sr.shape)\n",
        "      loss_im = image_crit(image_sr , images_hr).mean() * 100\n",
        "\n",
        "      loss_im.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "      optimizer_G.step()\n",
        "\n",
        "      torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "smwWSuJGrF66"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TSRN(scale_factor=1 , width=image_Width , height=image_Height , STN=False , srb_nums=srb , mask=False , hidden_units=hd_u)"
      ],
      "metadata": {
        "id": "ZbJRNJ11uKlG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "fhn0zAVkrMYX",
        "outputId": "f0e60c50-7cb3-438c-9b21-be36ee66650e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epoch: 0\n",
            "torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256])\n",
            "torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256])\n",
            "torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256])\n",
            "torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256]) torch.Size([4, 3, 256, 256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9d3046b5d0d4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-373fc4a3c774>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of epoch:\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#verify that model is training instead of evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bdcc0d66c3fe>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblur_dir\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"%d.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mblur_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M58nHKMGxmTv"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyoE5j3sLX42"
      },
      "source": [
        "def eval(model):\n",
        "  eval_dataset = MyDataset(eval_path)\n",
        "  eval_loader = torch.utils.data.DataLoader(\n",
        "      eval_dataset, batch_size = BatchSize, shuffle = True, collate_fn = alignCollate_syn(imgH = image_Height, imgW= image_Width, down_sample_scale=downSample, mask = True), drop_last = True\n",
        "  )\n",
        "\n",
        "  image_crit = ImageLoss(gradient=grd, loss_weight=[1 , 1e-4])\n",
        "  image_crit = image_crit.to(device)\n",
        "\n",
        "  loss_list = []\n",
        "\n",
        "  model.eval()\n",
        "  for j, data in (enumerate(eval_loader)):\n",
        "    for p in model.parameters():\n",
        "      p.requires_grad = False\n",
        "\n",
        "    images_hr , images_lr = data\n",
        "    images_lr = images_lr.to(device)\n",
        "    images_hr = images_hr.to(device)\n",
        "\n",
        "    images_sr = model(images_lr)\n",
        "    loss_im_eval = image_crit(images_sr,images_hr).mean() * 100\n",
        "    loss_list.append(loss_im_eval.item())\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  eval_loss.append(sum(loss_list)/len(loss_list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ0god3EVPu9"
      },
      "source": [
        "def train():\n",
        "  # model = TSRN(scale_factor=downSample , width=image_Width , height=image_Height , STN=False , srb_nums=srb , mask=True , hidden_units=hd_u)\n",
        "  # model = model.to(device)\n",
        "  image_crit = ImageLoss(gradient=grd, loss_weight=[1 , 1e-4])\n",
        "  image_crit = image_crit.to(device)\n",
        "  # optimizer_G = torch.optim.Adam(model.parameters() , lr=learning_rate , betas=(beta1,0.999))\n",
        "\n",
        "  for epoch in range(5):\n",
        "    print(\"Number of epoch:\" , epoch)\n",
        "    for j, data in (enumerate(train_loader)):\n",
        "      # model.train() #verify that model is training instead of evaluating\n",
        "\n",
        "      # for p in model.parameters():\n",
        "      #   p.requires_grad = True\n",
        "      iters = len(train_loader) * epoch + j + 1\n",
        "\n",
        "      images_hr , images_lr = data\n",
        "      print(images_hr.shape, images_lr.shape)\n",
        "\n",
        "      images_lr = images_lr.to(device)\n",
        "      images_hr = images_hr.to(device)\n",
        "\n",
        "      image_sr = model(images_lr)\n",
        "      loss_im = image_crit(image_sr , images_hr).mean() * 100\n",
        "\n",
        "      optimizer_G.zero_grad()\n",
        "      loss_im.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "      optimizer_G.step()\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      if j % 200 == 0:\n",
        "        print(\"Loss: \", loss_im)\n",
        "        training_loss.append(loss_im.item())\n",
        "        eval(model)\n",
        "\n",
        "  torch.save(model.state_dict(), 'TextZoom_jpeg_20.pkl')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkDwr7mEG_26"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWdsFp0mc85B",
        "outputId": "be394b4b-b1fb-4d9f-c8e6-ece9f73cc2af"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of epoch: 0\n",
            "Loss:  tensor(0.3407, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2385, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2926, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.3806, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Number of epoch: 1\n",
            "Loss:  tensor(0.2375, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2230, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2616, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.4981, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Number of epoch: 2\n",
            "Loss:  tensor(0.2680, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2108, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2186, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2472, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Number of epoch: 3\n",
            "Loss:  tensor(0.2306, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2207, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2104, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2808, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Number of epoch: 4\n",
            "Loss:  tensor(0.2154, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2228, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2706, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "Loss:  tensor(0.2326, device='cuda:0', grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI-jSqF9A6Ri"
      },
      "source": [
        "!mv \"TextZoom_jpeg_20.pkl\" \"/content/gdrive/MyDrive/UROP/TextZoom_Resource\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAkdc1qC5xgx"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz-UADv1ifPD",
        "outputId": "3613caa9-fc5c-4ec8-ef1b-182476af0fa4"
      },
      "source": [
        "print(training_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3407200276851654, 0.23846390843391418, 0.292585551738739, 0.38058358430862427, 0.23746195435523987, 0.22299450635910034, 0.26159611344337463, 0.4981400966644287, 0.26797497272491455, 0.2107529491186142, 0.21859526634216309, 0.24718481302261353, 0.23062452673912048, 0.2207319438457489, 0.2104347050189972, 0.2807972729206085, 0.21538051962852478, 0.2227843999862671, 0.2705560028553009, 0.232627272605896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad4vZW1ygw_V",
        "outputId": "238b62eb-474c-4813-94c6-9e872186c007"
      },
      "source": [
        "print(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7288363056798135, 0.30718324597804775, 0.24100508300527448, 0.3431440947517272, 0.2529895533957789, 0.2433093315170657, 0.241759616521097, 0.4990884277128404, 0.2851216908424131, 0.22811326360510242, 0.2830749094005554, 0.27848881218702565, 0.22867049565238337, 0.2232264131307602, 0.2243612843655771, 0.24536622700191313, 0.25195197256342056, 0.23516180919062707, 0.25008633973137023, 0.4217529373784219]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VCMw5qDgzMg"
      },
      "source": [
        "training_loss = [0.3407200276851654, 0.23846390843391418, 0.292585551738739, 0.38058358430862427]\n",
        "eval_loss = [0.7288363056798135, 0.30718324597804775, 0.24100508300527448, 0.3431440947517272]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "knJCby1hhYrr",
        "outputId": "52a56b1d-cf44-4191-f417-2a91b99844ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(np.linspace(1, len(training_loss) , len(training_loss))/5, training_loss)\n",
        "plt.plot(np.linspace(1, len(eval_loss) , len(eval_loss))/5, eval_loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.savefig('result.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPD4j2Igh7PC"
      },
      "source": [
        "#Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh_1u6Ox5z4p",
        "outputId": "50314206-6201-4d59-8db5-680bceb8c859"
      },
      "source": [
        "model_eval = TSRN(scale_factor=downSample , width=image_Width , height=image_Height , STN=False , srb_nums=srb , mask=True , hidden_units=hd_u)\n",
        "model_eval.load_state_dict(torch.load('gdrive/MyDrive/UROP/TextZoom_Resource/TextZoom_jpeg_20.pkl'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bxLIQSH6O0B"
      },
      "source": [
        "model_eval = model_eval.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu1Yw_tk6lHq"
      },
      "source": [
        "eval_img = Image.open(\"/content/content/eval_jpeg/screenshot00053.jpeg\")\n",
        "eval_img = eval_img.resize((image_Height // downSample, image_Width // downSample) , Image.BICUBIC)\n",
        "img_tensor = transforms.ToTensor()(eval_img)\n",
        "\n",
        "#add mask\n",
        "mask = eval_img.convert('L')\n",
        "thres = np.array(mask).mean()\n",
        "mask = mask.point(lambda x: 0 if x > thres else 255)\n",
        "mask = transforms.ToTensor()(mask)\n",
        "img_tensor = torch.cat((img_tensor, mask), 0)\n",
        "\n",
        "img_lr = img_tensor.unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHBc8Opr7qwG"
      },
      "source": [
        "img_lr = img_lr.to(device)\n",
        "img_sr = model_eval(img_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgiBEdth72UN"
      },
      "source": [
        "#將 tensor 改成 ndarray\n",
        "img_save = img_sr[0]*255\n",
        "img_save = np.transpose(img_save.cpu().detach().numpy() , (1,2,0))\n",
        "img_save = img_save[: , : , 0:3]\n",
        "img_save = np.array(img_save, dtype=np.uint8)\n",
        "\n",
        "#網路抄來的...不知道為什麼要if\n",
        "if np.ndim(img_save)>3:\n",
        "  assert img_save.shape[0] == 1\n",
        "  img_save = img_save[0]\n",
        "\n",
        "img_save = Image.fromarray(img_save , \"RGB\")\n",
        "img_save.save('output.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZlpmZa8Htj"
      },
      "source": [
        "blur_img = eval_img.resize((image_Height, image_Width), Image.BICUBIC)\n",
        "blur_img.save('blur.jpeg')\n",
        "eval_img.save('small.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfgYCNtA6FOD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}